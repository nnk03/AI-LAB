{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, collections, re, math, numpy as np, matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Node:\n",
    "#   def __init__(self, variable_name: int, parent_list: list, table_dictionary: dict) -> None:\n",
    "#     self.variable = variable_name\n",
    "#     self.parent_list = parent_list\n",
    "#     self.num_parents = len(parent_list)\n",
    "#     num_rows_of_table = 2**len(parent_list)\n",
    "#     self.num_rows_of_table = num_rows_of_table\n",
    "#     self.table_dictionary = table_dictionary\n",
    "#     self.parent_nodes = None\n",
    "#     self.children_nodes = None\n",
    "\n",
    "#   def set_parent_children(self, parent_list: list, children_list: list):\n",
    "#     self.parent_nodes = parent_list\n",
    "#     self.children_nodes = children_list\n",
    "\n",
    "\n",
    "#   def print_node(self):\n",
    "#     print(f'Variable name is {self.variable}')\n",
    "#     print('Parent List is')\n",
    "#     for parent in self.parent_list:\n",
    "#       print(parent)\n",
    "#     print('Table is ')\n",
    "#     for key in self.table_dictionary.keys():\n",
    "\n",
    "#       # x = bin(key)\n",
    "#       # x = x[2:].zfill(self.num_parents)\n",
    "#       # lst = [\n",
    "#       #   True if int(ch) else False for ch in x\n",
    "#       # ]\n",
    "#       # probability_lst = self.table_dictionary[key]\n",
    "#       # # print(key)\n",
    "#       # if self.num_parents != 0:\n",
    "#       #   x = bin(key)\n",
    "#       #   x = x[2:].zfill(self.num_parents)\n",
    "#       #   lst = [\n",
    "#       #     True if int(ch) else False for ch in x\n",
    "#       #   ]\n",
    "#       #   print(f'{self.variable} = True given {self.parent_list} = {lst} is {probability_lst[0]}')\n",
    "#       #   print(f'{self.variable} = False given {self.parent_list} = {lst} is {probability_lst[1]}')\n",
    "#       # else:\n",
    "#       #   print(f'{self.variable} = True is {probability_lst[0]}')\n",
    "#       #   print(f'{self.variable} = False is {probability_lst[1]}')\n",
    "\n",
    "#       print(key, self.table_dictionary[key])\n",
    "\n",
    "#       # print(self.table_dictionary[key])\n",
    "#       # print(key)\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# name, *parent_list = map(int, input().split())\n",
    "# print(name, parent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Graph:\n",
    "#   def __init__(self, file_path: str) -> None:\n",
    "#     file_object = open(file_path, 'r')\n",
    "#     text_lines = file_object.readlines()\n",
    "#     if not text_lines:\n",
    "#       print('File is Empty')\n",
    "#       return\n",
    "#     num_of_variables = int(text_lines[0])\n",
    "#     # print(num_of_variables)\n",
    "#     self.number_of_variables = num_of_variables\n",
    "#     self.number_of_vertices = num_of_variables\n",
    "#     num_lines = len(text_lines)\n",
    "\n",
    "#     for i in range(num_lines):\n",
    "#       text_lines[i] = text_lines[i].strip('\\n')\n",
    "#       # print(text_lines[i])\n",
    "    \n",
    "#     index = 1\n",
    "#     # print(text_lines[index])\n",
    "#     # print(text_lines[index+1])\n",
    "#     vertices_dictionary = dict()\n",
    "#     while index < num_lines:\n",
    "#       name, *parent_list = map(int, text_lines[index].split())\n",
    "#       num_rows_of_table = 2**len(parent_list)\n",
    "#       table_index = num_rows_of_table - 1\n",
    "#       table_dictionary = dict()\n",
    "#       while table_index > -1:\n",
    "#         # key has to be a tuple of tuple\n",
    "#         # (query_tuple, evidence_tuple)\n",
    "\n",
    "#         key_in_binary = bin(table_index)[2:].zfill(len(parent_list))\n",
    "\n",
    "#         # query = tuple([name])\n",
    "#         # evidence_list = [\n",
    "#         #   '+' + str(e) if \n",
    "#         # ]\n",
    "\n",
    "#         # print(key_in_binary) if len(parent_list) else None\n",
    "#         lst = list(map(float, text_lines[index + 1].split()))\n",
    "#         # print(lst)\n",
    "#         evidence_list = [\n",
    "#           (parent_list[i]) if int(key_in_binary[i]) else int('-' + str(parent_list[i])) for i in range(len(parent_list))\n",
    "#         ]\n",
    "#         # table_dictionary[table_index] = lst\n",
    "#         table_dictionary[(tuple([name]), tuple(evidence_list))] = lst[0]\n",
    "#         table_dictionary[(tuple([-name]), tuple(evidence_list))] = lst[1]\n",
    "#         # print(table_dictionary[table_index])\n",
    "#         index += 1\n",
    "#         table_index -= 1\n",
    "#         if index > num_lines:\n",
    "#           break\n",
    "#       vertices_dictionary[name] = Node(name, parent_list, table_dictionary)\n",
    "#       if index > num_lines:\n",
    "#         break\n",
    "      \n",
    "#       index += 1\n",
    "#     self.vertices_dictionary = vertices_dictionary\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "#   def print_graph(self):\n",
    "#     print(self.vertices_dictionary)\n",
    "#     for key, value in self.vertices_dictionary.items():\n",
    "#       print(f'Variable is {key}')\n",
    "#       if isinstance(value, Node):\n",
    "#         value.print_node()\n",
    "  \n",
    "#   def factorisation(self):\n",
    "#     print('Joint Probability is ')\n",
    "#     for key, value in self.vertices_dictionary.items():\n",
    "    \n",
    "#       if isinstance(value, Node):\n",
    "#         if value.parent_list:\n",
    "#           print(f'Probability of {key} given', end=' ')\n",
    "#         else:\n",
    "#           print(f'Probability of {key}', end=' ')\n",
    "#         for val in value.parent_list:\n",
    "#           print(val, end=' ')\n",
    "#       print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g1 = Graph('./Baynes_net_optional_files/7_b1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g1.print_graph()\n",
    "# # del g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = bin(123)\n",
    "# x = x[2:].zfill(10)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BN_Agent:\n",
    "#   def __init__(self,file_path: str) -> None:\n",
    "#     self.file_path = file_path\n",
    "#     self.graph = Graph(file_path)\n",
    "#     distribution = dict()\n",
    "#     for key in self.graph.vertices_dictionary.keys():\n",
    "#       node = self.graph.vertices_dictionary[key]\n",
    "#       if isinstance(node, Node):\n",
    "#         if isinstance(node.table_dictionary, dict):\n",
    "#           distribution.update(node.table_dictionary)\n",
    "  \n",
    "#     self.distribution = distribution\n",
    "\n",
    "#   def rejection_sampling(self, q: list, e: list, n: int):\n",
    "#     # q and e -> list of int\n",
    "#     q_set = set(q)\n",
    "#     e_set = set(e)\n",
    "#     graph = self.graph\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#   def print_distribution(self):\n",
    "#     for key, value in self.distribution.items():\n",
    "#       print(key,value)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# agent = BN_Agent('./Baynes_net_optional_files/7_b1.txt')\n",
    "\n",
    "# # print(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.print_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Vertex:\n",
    "  def __init__(self, variable_name: int) -> None:\n",
    "    self.variable = variable_name\n",
    "    self.cpt_table = None\n",
    "  \n",
    "  def set_cpt_table(self, cpt: dict()):\n",
    "    self.cpt_table = cpt\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bayesian_Network:\n",
    "  def __init__(self,file_path: str) -> None:\n",
    "    lines = []\n",
    "    with open(file_path, 'r') as file:\n",
    "      lines = file.readlines()\n",
    "    if not lines:\n",
    "      print('File is Empty')\n",
    "      return\n",
    "    num_lines = len(lines)\n",
    "    for i in range(num_lines):\n",
    "      lines[i] = lines[i].strip('\\n')\n",
    "    parent_dictionary = dict()\n",
    "\n",
    "    self.distribution = dict()\n",
    "    line_index = 0\n",
    "    while line_index < num_lines:\n",
    "      if line_index == 0:\n",
    "        num_of_variables = int(lines[line_index])\n",
    "        self.number_of_variables = num_of_variables\n",
    "        adj_dictionary = dict()\n",
    "        vertices_dictionary = dict()\n",
    "        for i in range(num_of_variables):\n",
    "          adj_dictionary[i+1] = set()\n",
    "          vertices_dictionary[i+1] = Vertex(i+1)\n",
    "        self.adj_dictionary = adj_dictionary\n",
    "        self.vertices_dictionary = vertices_dictionary\n",
    "\n",
    "        line_index += 1\n",
    "      else:\n",
    "        name, *parent_list = map(int, lines[line_index].split())\n",
    "        if not parent_list:\n",
    "          cpt = dict()\n",
    "          # index = 1\n",
    "          # for j in range(2)\n",
    "          line_index += 1\n",
    "          prob_dist = list(map(float, lines[line_index].split()))\n",
    "          cpt[((name,),())] = prob_dist[0]\n",
    "          cpt[((-name,),())] = prob_dist[1]\n",
    "          vertex = self.vertices_dictionary[name]\n",
    "          if isinstance(vertex, Vertex):\n",
    "            vertex.set_cpt_table(cpt)\n",
    "          line_index += 1\n",
    "          self.distribution.update(cpt)\n",
    "          parent_dictionary[name] = []\n",
    "          continue\n",
    "        else:\n",
    "          index = 2**len(parent_list)-1\n",
    "          line_index += 1\n",
    "          cpt = dict()\n",
    "          \n",
    "          while index > -1:\n",
    "            # cpt[((name),())]\n",
    "            key_in_binary = bin(index)[2:].zfill(len(parent_list))\n",
    "            lst = list(map(float, lines[line_index].split()))\n",
    "            truth_values = [\n",
    "              int(parent_list[i]) if int(key_in_binary[i]) else -(int(parent_list[i])) for i in range(len(key_in_binary))\n",
    "            ]\n",
    "            cpt[(tuple([name]), tuple(truth_values))] = lst[0]\n",
    "            cpt[(tuple([-name]), tuple(truth_values))] = lst[1]\n",
    "            index -= 1\n",
    "            line_index += 1\n",
    "          vertex = self.vertices_dictionary[name]\n",
    "          if isinstance(vertex, Vertex):\n",
    "            vertex.set_cpt_table(cpt)\n",
    "\n",
    "          [\n",
    "            self.addEdge(parent, name) for parent in  parent_list\n",
    "          ]\n",
    "          parent_dictionary[name] = list(parent_list)\n",
    "          self.distribution.update(cpt)\n",
    "          continue\n",
    "    self.parent_dictionary = parent_dictionary\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    # self.time = 0\n",
    "    self.topo_list = []\n",
    "    self.isVisited = dict()\n",
    "    for i in range(num_of_variables):\n",
    "      self.isVisited[i+1] = False\n",
    "    self.topo_ordering()\n",
    "\n",
    "    \n",
    "    # for key, value in self.vertices_dictionary:\n",
    "\n",
    "\n",
    "  def topo_ordering(self):\n",
    "    for i in range(self.number_of_variables):\n",
    "      if self.isVisited[i+1] == False:\n",
    "        # print('going to ', i+1)\n",
    "        self.dfs_explore(i+1)\n",
    "\n",
    "    self.topo_list.reverse()\n",
    "\n",
    "  def dfs_explore(self, vertex: int):\n",
    "    # self.time += 1\n",
    "    # print('came to ', vertex)\n",
    "    neighbours = self.adj_dictionary[vertex]\n",
    "    self.isVisited[vertex] = True\n",
    "    # print(neighbours)\n",
    "    for neighbour in list(neighbours):\n",
    "\n",
    "      if self.isVisited[neighbour] == False:\n",
    "        # print(f'going to {neighbour}')\n",
    "        self.dfs_explore(neighbour)\n",
    "    # print(f'returning from {vertex}')\n",
    "    self.topo_list.append(vertex)\n",
    "    # print(self.topo_list)\n",
    "\n",
    "  def print_topo_ordering(self):\n",
    "    print(self.topo_list)\n",
    "\n",
    "  def print_network(self):\n",
    "    for key, value in self.vertices_dictionary.items():\n",
    "      print('Variable is ', key)\n",
    "      if isinstance(value, Vertex):\n",
    "        z = value.cpt_table\n",
    "        if isinstance(z, dict):\n",
    "          for a,b in z.items():\n",
    "            print(a,b)\n",
    "\n",
    "\n",
    "\n",
    "    # self.read_file(file_path)\n",
    "\n",
    "  def print_adj_dictionary(self):\n",
    "    for key, value in self.adj_dictionary.items():\n",
    "      print(key, value)\n",
    "\n",
    "  def addEdge(self, x: int, y: int):\n",
    "    # edge from x to y\n",
    "    try:\n",
    "      z = self.adj_dictionary[x]\n",
    "      if isinstance(z, set):\n",
    "        z.add(y)\n",
    "    except:\n",
    "      print(f'No such vertex named {x}')\n",
    "  \n",
    "  # def read_file(self, file_path: str):\n",
    "\n",
    "  def parents(self, vertex: int):\n",
    "    try:\n",
    "      x = self.parent_dictionary[vertex]\n",
    "      return x\n",
    "    except:\n",
    "      return None\n",
    "    \n",
    "  def prior_sample(self):\n",
    "    topo_list = self.topo_list\n",
    "    x = [None for _ in range(self.number_of_variables + 1)]\n",
    "    # print(topo_list)\n",
    "    table = self.distribution\n",
    "    for vertex in topo_list:\n",
    "      parent_list = self.parents(vertex)\n",
    "      # print(parent_list)\n",
    "      if not parent_list:\n",
    "        prior_prob_vertex = table[((vertex,), ())]\n",
    "        isTrue = np.random.choice(a=[True, False], p=[prior_prob_vertex,1-prior_prob_vertex])\n",
    "        # print(isTrue)\n",
    "        if isTrue:\n",
    "          x[vertex] = vertex\n",
    "        else:\n",
    "          x[vertex] = -vertex\n",
    "        # print(x[vertex])\n",
    "      else:\n",
    "        key_required_set = set(\n",
    "          [\n",
    "            x[parent] for parent in parent_list\n",
    "          ]\n",
    "        )\n",
    "        # print(key_required_set)\n",
    "        for key in self.distribution.keys():\n",
    "          if key[0] == tuple([vertex]) and set(key[1]) == key_required_set:\n",
    "            # print(key)\n",
    "            prob_v_given_parents = table[key]\n",
    "            isTrue = np.random.choice(a=[True, False], p=[prob_v_given_parents,1-prob_v_given_parents])\n",
    "            if isTrue:\n",
    "              x[vertex] = vertex\n",
    "            else:\n",
    "              x[vertex] = -vertex\n",
    "            break\n",
    "    return x[1:]\n",
    "          \n",
    "\n",
    "\n",
    "  def rejection_sampling(self,query_list: list, evidence_list: list, n: int):\n",
    "    q_set = set(query_list)\n",
    "    e_set = set(evidence_list)\n",
    "\n",
    "    consistent_samples = []\n",
    "\n",
    "    for _ in range(n):\n",
    "      x = self.prior_sample()\n",
    "      evidence_set_obtained = set()\n",
    "      for index in evidence_list:\n",
    "        evidence_set_obtained.add(x[abs(index) - 1])\n",
    "      if evidence_set_obtained == e_set:\n",
    "        consistent_samples.append(x)\n",
    "\n",
    "    count = 0\n",
    "    total_consistent_samples = len(consistent_samples)\n",
    "    for sample in consistent_samples:\n",
    "      query_set_obtained = set()\n",
    "      for index in query_list:\n",
    "        query_set_obtained.add(sample[abs(index) - 1])\n",
    "        if query_set_obtained == q_set:\n",
    "          count += 1\n",
    "    del consistent_samples\n",
    "    return count/total_consistent_samples      \n",
    "  \n",
    "    \n",
    "  def variable_elimination(self, query_list: list, evidence_list: list):\n",
    "    q_set = set(query_list)\n",
    "    e_set = set(evidence_list)\n",
    "    non_e_set = set([\n",
    "      -variable for variable in evidence_list\n",
    "    ])\n",
    "    initial_factors = dict()\n",
    "    for key in self.distribution.keys():\n",
    "      # print(e_set, key[1])\n",
    "      check_set = set(key[1])\n",
    "\n",
    "      if not check_set:\n",
    "        initial_factors[key] = self.distribution[key]\n",
    "        continue\n",
    "      \n",
    "      isContinue = False\n",
    "      for v in e_set:\n",
    "        if -v in check_set:\n",
    "          isContinue = True\n",
    "          break\n",
    "      if isContinue:\n",
    "        continue\n",
    "      else:\n",
    "        initial_factors[key] = self.distribution[key]\n",
    "\n",
    "      \n",
    "      # for truth_value in e_set:\n",
    "      #   if -truth_value in check_set:\n",
    "      #     del check_set\n",
    "      #     continue\n",
    "      # initial_factors[key] = self.distribution[key]\n",
    "\n",
    "      del check_set\n",
    "    # print(initial_factors)\n",
    "    # for key, value in initial_factors.items():\n",
    "    #   print(key, value)\n",
    "\n",
    "    # finding the hidden variables\n",
    "    variable_set = set(\n",
    "      [\n",
    "        i+1 for i in range(self.number_of_variables)\n",
    "      ]\n",
    "    )\n",
    "    evidence_variables = set(\n",
    "      [\n",
    "        abs(variable) for variable in evidence_list\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    query_variables = set(\n",
    "      [\n",
    "        abs(variable) for variable in query_list\n",
    "      ]\n",
    "    )\n",
    "\n",
    "\n",
    "    hidden_variables = variable_set.difference(evidence_variables.union(query_variables))\n",
    "    # print(hidden_variables)\n",
    "\n",
    "    # for a,b in initial_factors.items():\n",
    "    #   print(a,b)\n",
    "\n",
    "    while hidden_variables:\n",
    "      h = hidden_variables.pop()\n",
    "      print(h)\n",
    "      factors_containing_true_h = dict()\n",
    "      factors_containing_false_h = dict()\n",
    "      for key in initial_factors.keys():\n",
    "        # print(key)\n",
    "        a = set(key[0])\n",
    "        b = set(key[1])\n",
    "        # print(a,b)\n",
    "        if h in a or h in b:\n",
    "          factors_containing_true_h[key] = initial_factors[key]\n",
    "        elif -h in a or -h in b:\n",
    "          factors_containing_false_h[key] = initial_factors[key]\n",
    "        # else:\n",
    "        #   factors_containing_true_h[key] = self.distribution[key]\n",
    "        #   factors_containing_false_h[key] = self.distribution[key]\n",
    "      for c,d in factors_containing_true_h.items():\n",
    "        print(c,d)\n",
    "      print()\n",
    "      for c,d in factors_containing_false_h.items():\n",
    "        print(c,d)\n",
    "\n",
    "      break\n",
    "\n",
    "  def check_present(self, a: set, b: set):\n",
    "    check = set([\n",
    "      -v for v in a\n",
    "    ])\n",
    "    for x in check:\n",
    "      if x in b:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "  def variable_enumeration(self, query_list: list, evidence_list: list):\n",
    "    # X = [abs(x) for x in query_list]\n",
    "    return self.enumeration_ask(query_list, evidence_list)\n",
    "\n",
    "\n",
    "  def enumeration_ask(self, X: list, e: list) -> float:\n",
    "    Q_distribution = dict()\n",
    "    absolute_X = [\n",
    "      abs(x) for x in X\n",
    "    ]\n",
    "    number_of_truth_values = 2**len(X)\n",
    "    length = len(X)\n",
    "    lst_of_truth_values = [\n",
    "      bin(i)[2:].zfill(length) for i in range(number_of_truth_values - 1, -1, -1)\n",
    "    ]\n",
    "    # print(lst_of_truth_values)\n",
    "    variables_of_network = self.topo_list\n",
    "    # variables_of_network.extend([\n",
    "    #   -i-1 for i in range(self.number_of_variables)\n",
    "    # ])\n",
    "    for truth_value in lst_of_truth_values:\n",
    "      key_list = [\n",
    "        absolute_X[i] if int(truth_value[i])  else -absolute_X[i] for i in range(len(truth_value))\n",
    "      ]\n",
    "      # print(key_list)\n",
    "\n",
    "\n",
    "      # some problem here\n",
    "      Q_distribution[tuple(key_list)] = self.enumerate_all(variables_of_network,list(set([*e, *key_list])))\n",
    "    \n",
    "\n",
    "    normalization_constant = sum(Q_distribution.values())\n",
    "    numerator = 0\n",
    "    for key in Q_distribution.keys():\n",
    "      if set(key) == set(X):\n",
    "        numerator = Q_distribution[key]\n",
    "        break\n",
    "\n",
    "    # print(Q_distribution)\n",
    "    del Q_distribution\n",
    "    # print(numerator, normalization_constant)\n",
    "    return numerator/normalization_constant\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def enumerate_all(self, variables: list, e: list):\n",
    "    # print(variables, e)\n",
    "    if not variables:\n",
    "      return 1\n",
    "    y = variables[0]\n",
    "    if y in e and -y in e:\n",
    "      return 0\n",
    "    if y in e:\n",
    "      # print('y in e')\n",
    "      for key in self.distribution.keys():\n",
    "        # print(3)\n",
    "        if key[0] == tuple([y]):\n",
    "          # print('here')\n",
    "          return self.distribution[key] * self.enumerate_all(variables[1:], e)\n",
    "    elif -y in e:\n",
    "      # print('-y in e')\n",
    "      for key in self.distribution.keys():\n",
    "        # print(3)\n",
    "        if key[0] == tuple([-y]):\n",
    "          # print('here negation')\n",
    "          return self.distribution[key] * self.enumerate_all(variables[1:], e)\n",
    "    else:\n",
    "      for key in self.distribution.keys():\n",
    "        if key[0] == tuple([abs(y)]):\n",
    "          return self.distribution[key] * self.enumerate_all(variables[1:], list(set([*e, *key[0]]))) + self.distribution[((-abs(y),), key[1])] * self.enumerate_all(variables[1:], list(set([*e, abs(key[0][0])])))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2 = Bayesian_Network('./Baynes_net_optional_files/7_b3.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g2.variable_enumeration([7],[-2,3,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Bayesian_Network('./Baynes_net_optional_files/7_b1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# giving wrong answer\n",
    "g.variable_enumeration(query_list=[2,3], evidence_list=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g.prior_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g.rejection_sampling(query_list=[-1,-2,-4,-5], evidence_list=[], n = int(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 2, 4]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.topo_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g.variable_elimination(query_list=[4,5], evidence_list=[-1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g3 = Bayesian_Network('./Baynes_net_optional_files/7_b2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g3.variable_elimination(query_list=[5], evidence_list=[2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g.variable_elimination(query_list=[5], evidence_list=[2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n",
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "a = (1,2,)\n",
    "print(*a)\n",
    "lst = [*a]\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(bn_file_path: str, q_file_path: str, ans_file_path: str):\n",
    "  graph = Bayesian_Network(bn_file_path)\n",
    "  with open(q_file_path, 'r') as q_file:\n",
    "    with open(ans_file_path,'w') as ans_file:\n",
    "      question = q_file.readline()\n",
    "      while question:\n",
    "        question_list = question.split()\n",
    "        # print(question_list)\n",
    "        \n",
    "        q_index = question_list.index('q')\n",
    "        e_index = question_list.index('e')\n",
    "        # print(q_index, e_index)\n",
    "        # print(question_list[q_index+1:e_index])\n",
    "        # print(question_list[e_index+1:])\n",
    "        query_list = [\n",
    "          -int(variable[1:]) if variable[0] == '~' else int(variable) for variable in question_list[q_index+1:e_index]\n",
    "        ]\n",
    "        evidence_list = [\n",
    "          -int(variable[1:]) if variable[0] == '~' else int(variable) for variable in question_list[e_index+1:]\n",
    "        ]\n",
    "        if question_list[0] == 've':\n",
    "          try:\n",
    "            ans_file.write(str(graph.variable_enumeration(query_list, evidence_list))+'\\n')\n",
    "          except:\n",
    "            ans_file.write(str(query_list) + str(evidence_list)+'\\n')\n",
    "            print(query_list, evidence_list)\n",
    "        elif question_list[0] == 'rs':\n",
    "          z = graph.rejection_sampling(query_list, evidence_list, 1000)\n",
    "          ans_file.write(str(z) + '\\n')\n",
    "          # print(z, graph.variable_enumeration(query_list,evidence_list))\n",
    "        question = q_file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer('./Baynes_net_optional_files/7_b1.txt','./Baynes_net_optional_files/7_q1.txt','./Baynes_net_optional_files/7_a1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer('./Baynes_net_optional_files/7_b2.txt','./Baynes_net_optional_files/7_q2.txt','./Baynes_net_optional_files/7_a2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7] [-2, 3, 5]\n"
     ]
    }
   ],
   "source": [
    "answer('./Baynes_net_optional_files/7_b3.txt','./Baynes_net_optional_files/7_q3.txt','./Baynes_net_optional_files/7_a3.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
